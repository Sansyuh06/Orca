{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orca: An Agentic Multi-Model Assistant for Stock Analysis & Forecasting\n",
    "\n",
    "**Google 5-Day AI Agents Intensive \u2013 Capstone Project**\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Orca is an AI stock analysis agent that helps users understand a stock from multiple angles: price history, technical indicators, ML forecasts, and natural-language explanations.\n",
    "\n",
    "The system is built using the **model + tools + orchestration** pattern from Google's agent architecture:\n",
    "- **Model**: Multi-LLM reasoning layer with judge-based selection\n",
    "- **Tools**: Python functions for data fetching, indicators, forecasting, and quantum-inspired risk\n",
    "- **Orchestration**: Think \u2192 Act \u2192 Observe cycle\n",
    "\n",
    "This notebook demonstrates sessions & memory, observability & evaluation, and an AI Canvas workflow visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Market data\n",
    "import yfinance as yf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Advanced Math\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    print(\"\u2713 Statsmodels imported for ARIMA\")\n",
    "except ImportError:\n",
    "    print(\"! Statsmodels not found, ARIMA will be disabled\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration & Helper Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IndicatorResult:\n",
    "    \"\"\"Result from technical indicator computation\"\"\"\n",
    "    df: pd.DataFrame\n",
    "    metrics: Dict[str, float]\n",
    "\n",
    "@dataclass\n",
    "class ForecastResult:\n",
    "    \"\"\"Result from ML forecast\"\"\"\n",
    "    direction: str        # \"UP\" or \"DOWN\"\n",
    "    expected_change_pct: float\n",
    "    confidence: float\n",
    "    horizon_days: int\n",
    "\n",
    "@dataclass\n",
    "class QuantumRiskResult:\n",
    "    \"\"\"Result from quantum-inspired risk analysis\"\"\"\n",
    "    quantum_risk: float\n",
    "    trade_probability: float\n",
    "\n",
    "@dataclass\n",
    "class AgentTraceEvent:\n",
    "    \"\"\"Single event in agent execution trace\"\"\"\n",
    "    step: int\n",
    "    component: str    # \"tool\", \"model\", \"judge\"\n",
    "    name: str\n",
    "    status: str\n",
    "    inputs: Dict[str, Any]\n",
    "    outputs: Dict[str, Any]\n",
    "    timestamp: float\n",
    "\n",
    "# Global trace log\n",
    "agent_trace: List[AgentTraceEvent] = []\n",
    "\n",
    "def log_event(component: str, name: str, status: str, inputs: Dict[str, Any], outputs: Dict[str, Any]):\n",
    "    \"\"\"Log an agent execution event for observability\"\"\"\n",
    "    agent_trace.append(\n",
    "        AgentTraceEvent(\n",
    "            step=len(agent_trace) + 1,\n",
    "            component=component,\n",
    "            name=name,\n",
    "            status=status,\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "            timestamp=time.time()\n",
    "        )\n",
    "    )\n",
    "    print(f\"[{component.upper()}] {name}: {status}\")\n",
    "\n",
    "print(\"\u2713 Data structures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent Tools \u2013 Data Fetching & Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_fetch_price_data(symbol: str, period=\"1y\", interval=\"1d\") -> pd.DataFrame:\n",
    "    \"\"\"Fetch OHLCV data for a symbol using yfinance.\"\"\"\n",
    "    df = yf.download(symbol, period=period, interval=interval, auto_adjust=True, progress=False)\n",
    "    df = df.dropna()\n",
    "    log_event(\"tool\", \"fetch_price_data\", \"ok\", {\"symbol\": symbol}, {\"rows\": len(df)})\n",
    "    return df\n",
    "\n",
    "def tool_compute_indicators(df: pd.DataFrame) -> IndicatorResult:\n",
    "    \"\"\"Compute advanced technical indicators from price data.\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Moving averages\n",
    "    data[\"MA20\"] = data[\"Close\"].rolling(20).mean()\n",
    "    data[\"MA50\"] = data[\"Close\"].rolling(50).mean()\n",
    "    \n",
    "    # Daily returns & volatility\n",
    "    data[\"returns\"] = data[\"Close\"].pct_change()\n",
    "    vol = data[\"returns\"].std() * np.sqrt(252) * 100\n",
    "    \n",
    "    # RSI\n",
    "    delta = data[\"Close\"].diff()\n",
    "    gain = delta.clip(lower=0).rolling(14).mean()\n",
    "    loss = -delta.clip(upper=0).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-9)\n",
    "    data[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = data[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = data[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    data[\"MACD\"] = ema12 - ema26\n",
    "    data[\"MACD_signal\"] = data[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb_std = data[\"Close\"].rolling(20).std()\n",
    "    data[\"BB_Upper\"] = data[\"MA20\"] + (bb_std * 2)\n",
    "    data[\"BB_Lower\"] = data[\"MA20\"] - (bb_std * 2)\n",
    "    data[\"BB_Pos\"] = (data[\"Close\"] - data[\"BB_Lower\"]) / (data[\"BB_Upper\"] - data[\"BB_Lower\"])\n",
    "    \n",
    "    # Williams %R\n",
    "    highest_high = data[\"High\"].rolling(14).max()\n",
    "    lowest_low = data[\"Low\"].rolling(14).min()\n",
    "    data[\"Williams_%R\"] = -100 * (highest_high - data[\"Close\"]) / (highest_high - lowest_low)\n",
    "    \n",
    "    # ATR\n",
    "    tr1 = data[\"High\"] - data[\"Low\"]\n",
    "    tr2 = abs(data[\"High\"] - data[\"Close\"].shift(1))\n",
    "    tr3 = abs(data[\"Low\"] - data[\"Close\"].shift(1))\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    data[\"ATR\"] = tr.rolling(14).mean()\n",
    "    \n",
    "    # Performance metrics\n",
    "    total_return = (data[\"Close\"].iloc[-1] / data[\"Close\"].iloc[0] - 1) * 100\n",
    "    sharpe = (data[\"returns\"].mean() / (data[\"returns\"].std() + 1e-9)) * np.sqrt(252)\n",
    "    \n",
    "    # Max drawdown\n",
    "    cum_max = data[\"Close\"].cummax()\n",
    "    drawdown = (data[\"Close\"] / cum_max) - 1\n",
    "    max_dd = drawdown.min() * 100\n",
    "    \n",
    "    metrics = {\n",
    "        \"volatility_pct\": float(vol),\n",
    "        \"total_return_pct\": float(total_return),\n",
    "        \"sharpe\": float(sharpe),\n",
    "        \"max_drawdown_pct\": float(max_dd),\n",
    "        \"rsi\": float(data[\"RSI\"].iloc[-1]),\n",
    "        \"macd\": float(data[\"MACD\"].iloc[-1]),\n",
    "        \"williams_r\": float(data[\"Williams_%R\"].iloc[-1]),\n",
    "        \"atr\": float(data[\"ATR\"].iloc[-1])\n",
    "    }\n",
    "    \n",
    "    log_event(\"tool\", \"compute_indicators\", \"ok\", {}, metrics)\n",
    "    return IndicatorResult(df=data, metrics=metrics)\n",
    "\n",
    "print(\"\u2713 Data fetching and advanced indicator tools defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Tools \u2013 ML Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_run_forecast(df: pd.DataFrame, horizon_days: int = 30) -> ForecastResult:\n",
    "    \"\"\"Run hybrid forecast (ARIMA + Linear Regression).\"\"\"\n",
    "    prices = df[\"Close\"].values\n",
    "    \n",
    "    # 1. Linear Regression (Trend)\n",
    "    X = np.arange(len(prices))\n",
    "    coeffs = np.polyfit(X, prices, 1)\n",
    "    m, b = coeffs\n",
    "    \n",
    "    future_X = np.arange(len(prices), len(prices) + horizon_days)\n",
    "    lin_pred = m * future_X + b\n",
    "    \n",
    "    # 2. ARIMA (Short-term dynamics)\n",
    "    try:\n",
    "        # Simple ARIMA(5,1,0) on recent data\n",
    "        model = ARIMA(prices[-100:], order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "        arima_forecast = model_fit.forecast(steps=horizon_days)\n",
    "        \n",
    "        # Combine: Average of both for robustness\n",
    "        final_pred = (lin_pred + arima_forecast) / 2\n",
    "        method = \"Hybrid (ARIMA + Linear)\"\n",
    "    except:\n",
    "        final_pred = lin_pred\n",
    "        method = \"Linear Regression\"\n",
    "    \n",
    "    expected_change_pct = (final_pred[-1] - prices[-1]) / prices[-1] * 100\n",
    "    \n",
    "    # Confidence based on R^2 of linear fit\n",
    "    pred_past = m * X + b\n",
    "    ss_res = np.sum((prices - pred_past) ** 2)\n",
    "    ss_tot = np.sum((prices - prices.mean()) ** 2) + 1e-9\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    confidence = float(np.clip(r2 * 100, 50, 95))\n",
    "    \n",
    "    direction = \"UP\" if expected_change_pct >= 0 else \"DOWN\"\n",
    "    \n",
    "    out = {\n",
    "        \"direction\": direction,\n",
    "        \"expected_change_pct\": expected_change_pct,\n",
    "        \"confidence\": confidence,\n",
    "        \"horizon_days\": horizon_days,\n",
    "    }\n",
    "    \n",
    "    log_event(\"tool\", \"run_forecast\", \"ok\", \n",
    "              {\"method\": method, \"horizon\": horizon_days}, out)\n",
    "    return ForecastResult(**out)\n",
    "\n",
    "print(\"\u2713 Hybrid ML forecast tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Tools \u2013 Quantum-Inspired Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_quantum_risk(indicators: IndicatorResult) -> QuantumRiskResult:\n",
    "    \"\"\"Compute quantum-inspired risk metrics.\n",
    "    \n",
    "    We scale volatility by 1.2 to model extra uncertainty, then convert it \n",
    "    into a probability with a 0.7 damping factor so values stay realistic.\n",
    "    \n",
    "    Args:\n",
    "        indicators: IndicatorResult with computed metrics\n",
    "    \n",
    "    Returns:\n",
    "        QuantumRiskResult with risk score and trade probability\n",
    "    \"\"\"\n",
    "    vol = indicators.metrics[\"volatility_pct\"]\n",
    "    quantum_risk = vol * 1.2            # amplify uncertainty slightly\n",
    "    trade_prob = max(0.0, 100.0 - 0.7 * quantum_risk)\n",
    "    \n",
    "    out = {\n",
    "        \"quantum_risk\": float(quantum_risk),\n",
    "        \"trade_probability\": float(trade_prob),\n",
    "    }\n",
    "    \n",
    "    log_event(\"tool\", \"quantum_risk\", \"ok\", {}, out)\n",
    "    return QuantumRiskResult(**out)\n",
    "\n",
    "print(\"\u2713 Quantum risk tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-LLM Orchestration & Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_expert_model(model_name: str, analysis_payload: Dict[str, Any]) -> str:\n",
    "    \"\"\"Simulate LLM expert model call.\n",
    "    \n",
    "    In production, this would call Gemini/GPT/Claude with a prompt that includes:\n",
    "    - Summary of indicators\n",
    "    - Forecast\n",
    "    - Quantum risk\n",
    "    - User question\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the expert model\n",
    "        analysis_payload: Complete analysis context\n",
    "    \n",
    "    Returns:\n",
    "        Generated text response\n",
    "    \"\"\"\n",
    "    # For demo, return a synthetic answer based on metrics\n",
    "    direction = analysis_payload[\"forecast\"][\"direction\"]\n",
    "    change_pct = analysis_payload[\"forecast\"][\"expected_change_pct\"]\n",
    "    quantum_risk = analysis_payload[\"quantum\"][\"quantum_risk\"]\n",
    "    \n",
    "    response = (\n",
    "        f\"As {model_name}, I see a {direction} trend with ~{change_pct:.2f}% change \"\n",
    "        f\"and quantum risk {quantum_risk:.1f}. This looks like a \"\n",
    "        f\"{'cautious buy' if direction=='UP' else 'cautious sell'}.\"\n",
    "    )\n",
    "    \n",
    "    log_event(\"model\", f\"expert_{model_name}\", \"ok\", \n",
    "              {\"model\": model_name}, {\"response_len\": len(response)})\n",
    "    \n",
    "    return response\n",
    "\n",
    "def judge_answers(judge_model: str, answers: Dict[str, str], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"LM-as-a-Judge pattern: score and rank expert answers.\n",
    "    \n",
    "    In production, this would send all answers to a judge LLM (e.g., DeepSeek-R1)\n",
    "    to evaluate quality, accuracy, and relevance.\n",
    "    \n",
    "    Args:\n",
    "        judge_model: Name of the judge model\n",
    "        answers: Dict mapping model names to their responses\n",
    "        context: Analysis context for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        Dict with scores and best answer\n",
    "    \"\"\"\n",
    "    scored = []\n",
    "    for model, text in answers.items():\n",
    "        # Heuristic scoring for demo (in production, use actual LLM judge)\n",
    "        score = 7.0 + np.random.uniform(-1, 2)  # Simulate variation\n",
    "        scored.append({\"model\": model, \"answer\": text, \"score\": score})\n",
    "    \n",
    "    best = max(scored, key=lambda x: x[\"score\"])\n",
    "    \n",
    "    log_event(\"model\", \"judge_answers\", \"ok\", \n",
    "              {\"n_models\": len(answers)}, {\"best_model\": best[\"model\"]})\n",
    "    \n",
    "    return {\"scores\": scored, \"best\": best}\n",
    "\n",
    "print(\"\u2713 Multi-LLM orchestration defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Agent Orchestration Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrcaAgent:\n",
    "    \"\"\"Main agent orchestrator implementing the Think \u2192 Act \u2192 Observe cycle.\"\"\"\n",
    "    \n",
    "    def __init__(self, expert_models: List[str], judge_model: str):\n",
    "        self.expert_models = expert_models\n",
    "        self.judge_model = judge_model\n",
    "        self.sessions = {}  # session_id -> history/memory (simple dict)\n",
    "    \n",
    "    def analyze_stock(self, session_id: str, symbol: str, question: str, horizon_days=30):\n",
    "        \"\"\"Execute full agent workflow for stock analysis.\n",
    "        \n",
    "        Args:\n",
    "            session_id: User session identifier\n",
    "            symbol: Stock ticker symbol\n",
    "            question: User's question about the stock\n",
    "            horizon_days: Forecast horizon in days\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (analysis_payload, judge_result)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"AGENT ANALYZING: {symbol}\")\n",
    "        print(f\"QUESTION: {question}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # 1) THINK: Fetch & compute (tool calls)\n",
    "        df = tool_fetch_price_data(symbol)\n",
    "        indicators = tool_compute_indicators(df)\n",
    "        forecast = tool_run_forecast(indicators.df, horizon_days=horizon_days)\n",
    "        quantum = tool_quantum_risk(indicators)\n",
    "        \n",
    "        # Combine numerical analysis into a single payload\n",
    "        analysis_payload = {\n",
    "            \"symbol\": symbol,\n",
    "            \"indicators\": indicators.metrics,\n",
    "            \"forecast\": asdict(forecast),\n",
    "            \"quantum\": asdict(quantum),\n",
    "            \"question\": question,\n",
    "        }\n",
    "        \n",
    "        # 2) ACT: Multi-LLM panel generates responses\n",
    "        answers = {}\n",
    "        for model_name in self.expert_models:\n",
    "            text = call_expert_model(model_name, analysis_payload)\n",
    "            answers[model_name] = text\n",
    "        \n",
    "        # 3) OBSERVE: Judge evaluates and selects best answer\n",
    "        judge_result = judge_answers(self.judge_model, answers, analysis_payload)\n",
    "        \n",
    "        # 4) MEMORY: Update session history\n",
    "        history = self.sessions.setdefault(session_id, [])\n",
    "        history.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"question\": question,\n",
    "            \"analysis\": analysis_payload,\n",
    "            \"judge_result\": judge_result,\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n\u2713 Analysis complete. Best model: {judge_result['best']['model']}\")\n",
    "        \n",
    "        return analysis_payload, judge_result\n",
    "\n",
    "print(\"\u2713 Agent orchestration class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demo Run \u2013 Analyze AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent with expert models\n",
    "agent = OrcaAgent(\n",
    "    expert_models=[\"Expert-A\", \"Expert-B\", \"Expert-C\"],\n",
    "    judge_model=\"Judge-1\"\n",
    ")\n",
    "\n",
    "# Run analysis\n",
    "analysis, judge_result = agent.analyze_stock(\n",
    "    session_id=\"demo_user_1\",\n",
    "    symbol=\"AAPL\",\n",
    "    question=\"Is this a good short-term buy for the next month?\",\n",
    "    horizon_days=30\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSymbol: {analysis['symbol']}\")\n",
    "print(f\"\\nIndicators:\")\n",
    "for key, value in analysis['indicators'].items():\n",
    "    print(f\"  {key}: {value:.2f}\")\n",
    "print(f\"\\nForecast:\")\n",
    "for key, value in analysis['forecast'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"\\nQuantum Risk:\")\n",
    "for key, value in analysis['quantum'].items():\n",
    "    print(f\"  {key}: {value:.2f}\")\n",
    "print(f\"\\nBest Answer (from {judge_result['best']['model']}):\")\n",
    "print(f\"  {judge_result['best']['answer']}\")\n",
    "print(f\"  Score: {judge_result['best']['score']:.2f}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization \u2013 Price Chart with Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data for visualization\n",
    "df = tool_fetch_price_data(\"AAPL\")\n",
    "ind_res = tool_compute_indicators(df)\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), \n",
    "                                gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Price chart with moving averages\n",
    "ax1.plot(ind_res.df.index, ind_res.df[\"Close\"], label=\"Close\", linewidth=2, color='#06b6d4')\n",
    "ax1.plot(ind_res.df.index, ind_res.df[\"MA20\"], label=\"MA20\", linewidth=1.5, \n",
    "         color='#f59e0b', linestyle='--')\n",
    "ax1.plot(ind_res.df.index, ind_res.df[\"MA50\"], label=\"MA50\", linewidth=1.5, \n",
    "         color='#8b5cf6', linestyle='--')\n",
    "ax1.set_title(\"AAPL Price with Moving Averages\", fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel(\"Price ($)\", fontsize=12)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RSI chart\n",
    "ax2.plot(ind_res.df.index, ind_res.df[\"RSI\"], label=\"RSI\", linewidth=2, color='#10b981')\n",
    "ax2.axhline(y=70, color='#ef4444', linestyle='--', linewidth=1, alpha=0.7, label='Overbought')\n",
    "ax2.axhline(y=30, color='#10b981', linestyle='--', linewidth=1, alpha=0.7, label='Oversold')\n",
    "ax2.set_title(\"Relative Strength Index (RSI)\", fontsize=14)\n",
    "ax2.set_ylabel(\"RSI\", fontsize=12)\n",
    "ax2.set_xlabel(\"Date\", fontsize=12)\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Observability \u2013 Agent Trace Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trace is our \"glass box\" view of the agent's trajectory, matching the Agent Quality whitepaper's idea of logging, tracing, and metrics.\n",
    "\n",
    "Each row represents a single step in the agent's execution, showing:\n",
    "- **Component**: Whether it's a tool call, model call, or judge decision\n",
    "- **Name**: Specific function or model invoked\n",
    "- **Status**: Success/failure status\n",
    "- **Timestamp**: When the event occurred\n",
    "\n",
    "This enables debugging, performance analysis, and understanding of the agent's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trace to DataFrame\n",
    "trace_df = pd.DataFrame([asdict(e) for e in agent_trace])\n",
    "trace_df = trace_df.sort_values(\"step\")\n",
    "\n",
    "# Display trace table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT EXECUTION TRACE\")\n",
    "print(\"=\"*80)\n",
    "print(trace_df[[\"step\", \"component\", \"name\", \"status\", \"timestamp\"]].to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nTotal steps: {len(trace_df)}\")\n",
    "print(f\"Tool calls: {len(trace_df[trace_df['component'] == 'tool'])}\")\n",
    "print(f\"Model calls: {len(trace_df[trace_df['component'] == 'model'])}\")\n",
    "print(f\"Total execution time: {trace_df['timestamp'].max() - trace_df['timestamp'].min():.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluation \u2013 Model Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display model scores\n",
    "scores_df = pd.DataFrame(judge_result['scores'])\n",
    "scores_df = scores_df.sort_values('score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION SCORES\")\n",
    "print(\"=\"*60)\n",
    "print(scores_df.to_string(index=False))\n",
    "\n",
    "# Visualize scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(scores_df['model'], scores_df['score'], color='#06b6d4')\n",
    "\n",
    "# Highlight best model\n",
    "best_idx = scores_df['score'].idxmax()\n",
    "bars[best_idx].set_color('#10b981')\n",
    "\n",
    "ax.set_xlabel('Score (0-10)', fontsize=12)\n",
    "ax.set_title('LLM Expert Model Scores (Judge Evaluation)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 10)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. AI Canvas \u2013 Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent workflow can be visualized as a directed graph:\n",
    "\n",
    "```\n",
    "User Question\n",
    "      |\n",
    "      v\n",
    "[Agent Orchestrator]\n",
    "      |\n",
    "      +--> [tool_fetch_price_data]\n",
    "      |\n",
    "      +--> [tool_compute_indicators]\n",
    "      |\n",
    "      +--> [tool_run_forecast]\n",
    "      |\n",
    "      +--> [tool_quantum_risk]\n",
    "      |\n",
    "      +--> [Expert LLM A]\n",
    "      +--> [Expert LLM B]\n",
    "      +--> [Expert LLM C]\n",
    "      |\n",
    "      +--> [Judge LLM]\n",
    "      |\n",
    "      v\n",
    "Final Answer + Report\n",
    "```\n",
    "\n",
    "In the full web application, this is visualized as an interactive drag-and-drop canvas with nodes and connections, similar to n8n or LangFlow. Users can:\n",
    "- See real-time execution status\n",
    "- Inspect inputs/outputs at each node\n",
    "- Modify the workflow by adding/removing models\n",
    "- Export the workflow configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Sessions & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate session memory\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SESSION MEMORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "session_history = agent.sessions.get(\"demo_user_1\", [])\n",
    "print(f\"\\nSession ID: demo_user_1\")\n",
    "print(f\"Total queries: {len(session_history)}\")\n",
    "\n",
    "for i, entry in enumerate(session_history, 1):\n",
    "    print(f\"\\nQuery {i}:\")\n",
    "    print(f\"  Symbol: {entry['symbol']}\")\n",
    "    print(f\"  Question: {entry['question']}\")\n",
    "    print(f\"  Best Model: {entry['judge_result']['best']['model']}\")\n",
    "    print(f\"  Score: {entry['judge_result']['best']['score']:.2f}\")\n",
    "\n",
    "# Simulate user preferences (memory)\n",
    "user_preferences = {\n",
    "    \"demo_user_1\": {\n",
    "        \"favorite_tickers\": [\"AAPL\", \"MSFT\", \"GOOGL\"],\n",
    "        \"risk_tolerance\": \"moderate\",\n",
    "        \"preferred_horizon\": 30,\n",
    "        \"last_active\": time.time()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nUser Preferences:\")\n",
    "for key, value in user_preferences[\"demo_user_1\"].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Portfolio Analysis (New Feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have added a new capability to analyze user-uploaded portfolios (PDFs, Images) using Gemini 2.0 Flash.\n",
    "\n",
    "The workflow is:\n",
    "1. User uploads portfolio document.\n",
    "2. System extracts text/images.\n",
    "3. Gemini analyzes holdings, risk, and market alignment using **Persona-Based Context Prompting**.\n",
    "4. Returns an **Executive Summary** with actionable advice.\n",
    "\n",
    "This feature is available in the web UI under the \"Portfolio Analysis\" panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusion & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We've Demonstrated\n",
    "\n",
    "This notebook showcases a complete AI agent architecture following the Google 5-Day Agents Intensive principles:\n",
    "\n",
    "1. **Agent Architecture** (Day 1): Think \u2192 Act \u2192 Observe cycle with clear separation of concerns\n",
    "2. **Agent Tools** (Day 2): Well-defined, documented tools with structured inputs/outputs\n",
    "3. **Sessions & Memory** (Day 3): Per-user context and preference storage\n",
    "4. **Observability & Evaluation** (Day 4): Complete execution traces and LM-as-a-Judge scoring\n",
    "5. **Production Readiness** (Day 5): Modular design ready for API deployment\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Multi-LLM orchestration** reduces hallucination and improves reliability\n",
    "- **Quantum-inspired signals** add novel risk assessment beyond classical indicators\n",
    "- **Transparent workflow** enables debugging and trust-building\n",
    "- **Agentic pattern** provides flexibility and extensibility\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "- **Real LLM Integration**: Connect to Gemini, GPT-4, or Claude APIs\n",
    "- **Advanced ML**: Replace linear regression with LSTM or Transformer models\n",
    "- **Real-time Data**: Stream live market data for intraday trading\n",
    "- **Portfolio Analysis**: Extend from single-stock to multi-asset portfolios\n",
    "- **Backtesting**: Validate forecast accuracy over historical periods\n",
    "- **Web Deployment**: Deploy as Flask/FastAPI service with React frontend\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Full Web Application**: See `app.py` for Flask implementation with AI Canvas\n",
    "- **Documentation**: See `README.md` for complete project overview\n",
    "- **Agent Whitepapers**: Google AI Agents Intensive course materials\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for reviewing Orca!**\n",
    "\n",
    "This project demonstrates how traditional quantitative finance, modern ML, and LLM reasoning can be combined into a transparent, inspectable AI agent suitable for educational and retail-investor use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. User Guide: How to Use Orca\n",
    "\n",
    "This section provides a step-by-step guide on how to run and interact with the Orca application.\n",
    "\n",
    "### Step 1: Installation & Setup\n",
    "1. **Clone the Repository**:\n",
    "   ```bash\n",
    "   git clone https://github.com/Sansyuh06/stocks.git\n",
    "   cd stocks\n",
    "   ```\n",
    "2. **Install Dependencies**:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. **Install Ollama Models** (for local AI):\n",
    "   ```bash\n",
    "   ollama pull mistral:7b\n",
    "   ollama pull llama3.1:8b\n",
    "   ollama pull phi3:mini\n",
    "   ollama pull deepseek-r1:7b\n",
    "   ```\n",
    "\n",
    "### Step 2: Running the Application\n",
    "1. Start the Flask server:\n",
    "   ```bash\n",
    "   python app.py\n",
    "   ```\n",
    "2. Open your web browser and navigate to:\n",
    "   `http://localhost:5000`\n",
    "\n",
    "### Step 3: Using the Dashboard\n",
    "1. **Select a Stock**: Use the dropdown menu or type a ticker symbol (e.g., `NVDA`).\n",
    "2. **Analyze**: Click the **\"Analyze Stock\"** button. The agent will:\n",
    "   - Fetch historical data.\n",
    "   - Calculate technical indicators (RSI, MACD, etc.).\n",
    "   - Run the ML forecast.\n",
    "3. **View Results**: Explore the interactive charts, risk metrics, and trading signals.\n",
    "4. **Get AI Consensus**: Select your preferred AI models (e.g., Mistral + Llama 3) and click **\"Get AI Consensus\"** to see a multi-perspective report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Component Deep Dive\n",
    "\n",
    "Understanding the core building blocks of the Orca architecture.\n",
    "\n",
    "### 1. The Orchestrator (ADK Agent)\n",
    "- **Role**: The \"brain\" of the system.\n",
    "- **Function**: It follows a **Think-Act-Observe** loop. It receives a user query, decides which tools to use, executes them, and synthesizes the results.\n",
    "- **Code**: Implemented in the `StockAnalyzer` class in `app.py`.\n",
    "\n",
    "### 2. The Tools\n",
    "Specialized Python functions that the agent can call:\n",
    "- **`fetch_data`**: Retrieves OHLCV market data from Yahoo Finance or Alpha Vantage.\n",
    "- **`calculate_advanced_indicators`**: Computes mathematical metrics like:\n",
    "  - **RSI**: Momentum oscillator.\n",
    "  - **Bollinger Bands**: Volatility measurement.\n",
    "  - **Williams %R**: Overbought/oversold levels.\n",
    "  - **ATR**: Market volatility.\n",
    "- **`forecast_short_term_price`**: A hybrid ML model combining **ARIMA** (statistical) and **Linear Regression** (trend) to predict future price direction.\n",
    "\n",
    "### 3. The Panel of Experts (Models)\n",
    "- **Role**: Diverse analytical perspectives.\n",
    "- **Implementation**: We use multiple small, specialized LLMs (via Ollama) instead of one giant model.\n",
    "  - **Mistral**: Good at general reasoning.\n",
    "  - **Phi-3**: Excellent for concise, data-driven summaries.\n",
    "  - **Llama 3**: Strong at structured, deep analysis.\n",
    "\n",
    "### 4. The Judge (Evaluator)\n",
    "- **Role**: Quality control.\n",
    "- **Model**: **DeepSeek-R1**.\n",
    "- **Function**: It reads the analysis from all experts and scores them (1-10) based on accuracy, depth, and actionability. Only the best response is shown to the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}